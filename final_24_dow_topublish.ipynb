{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18dbcaa1",
   "metadata": {},
   "source": [
    "# Python implementation for forecasting price of Dow Jones Industrial Average index using linear regression (LR), support vector regression (SVR), long short term memory (LSTM) neural network, artificial neural network (ANN), and stage two hybrid technique with all above four in stage 1 and LSTM in stage 2. Evaluating their forecasting performance using root mean square error (RMSE) and mean absolute percentage error (MAPE). Calculating the importance of inputs in forecasting the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9117663f",
   "metadata": {},
   "source": [
    "## Importing basic libraries like Numpy, Pandas, and others along with Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9cbe1817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pandas: 1.4.2\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import os.path\n",
    "from numpy.random import seed\n",
    "seed(11)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(12)\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(\"  pandas: %s\"% pd.__version__)\n",
    "except:\n",
    "    print(\"Missing pandas package\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4823e3cc",
   "metadata": {},
   "source": [
    "## Import yahoo finance API, and extract the stock index data from yahoo finance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4446db6",
   "metadata": {},
   "source": [
    "## NASDAQ 100, S&P 500, Dow Jones Industrial average are the important stock indices of United States of America (USA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2b1269f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1992-02-01     3267.699951\n",
       "1992-03-01     3235.500000\n",
       "1992-04-01     3359.100098\n",
       "1992-05-01     3396.899902\n",
       "1992-06-01     3318.500000\n",
       "                  ...     \n",
       "2022-03-01    34678.351562\n",
       "2022-04-01    32977.210938\n",
       "2022-05-01    32990.121094\n",
       "2022-06-01    30775.429688\n",
       "2022-07-01    32845.128906\n",
       "Name: Close, Length: 366, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "df = yf.download(\"^DJI\", start=\"1985-01-01\", end=\"2022-07-30\", interval=\"1mo\") \n",
    "data=df['Close']\n",
    "data\n",
    "# ^NDX is symbol for NASDAQ 100\n",
    "# ^GSPC is symbol for S&P 500\n",
    "# ^DJI is symbol for Dow Jones Industrial Average (it consists of 30 companies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808f949e",
   "metadata": {},
   "source": [
    "## Exponential moving average (EMA) is calculated with 90 percent weightage to the current value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad4c3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EMA']=df['Adj Close'].ewm(alpha=0.9).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faac34fe",
   "metadata": {},
   "source": [
    "## The onbalance volume (OBV) is calculated in below steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db778d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sign of price variation is calculated to get the know whether cash flow is positive or negative\n",
    "df['sign']=np.sign(df['Adj Close'].pct_change()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "299f597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sign']=df['sign']*df['Volume'] #now sign is multiplied with volume to get the volume effect of cash flow trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "888a57c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OBV']=np.cumsum(df['sign']) # the cumulative effect of volume of cash flow is obtained which is known as on-balance volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9490da",
   "metadata": {},
   "source": [
    "## Average true range (ATR) is calculated in below steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe1bca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the three different arguments of the true range are calculated and assigned to arbitrary variables a,b,c\n",
    "a=pd.DataFrame(df['High']-df['Low'])\n",
    "b=pd.DataFrame(abs(df['High']-df['Close'].shift(1)))\n",
    "c=pd.DataFrame(abs(df['High']-df['Close'].shift(1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "de28fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the three arguments of the true range are combined into a single dataframe\n",
    "a['1']=b\n",
    "a['2']=c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42a988f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr=a.max(axis=1) # true range (TR) is the maximum value amoung its three arguments \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f42479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TR']=tr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cadb7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ATR']=df['TR'].rolling(3).mean() # average true range (ATR) is calculated from true range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf79be",
   "metadata": {},
   "source": [
    "## The close price of the index is converted into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2737e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f56a6",
   "metadata": {},
   "source": [
    "## The name of the columns are changed inorder to be consistent with the remaining program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4251b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns = {'Close':'CLOSE'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d029e31",
   "metadata": {},
   "source": [
    "## The datareader function is imported for the purpose of remote data access. The Fama French five factor model data is read from their database. This Fama French data is for stocks markets in United States of America (USA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67ad6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "START_DATE = '1985-1-1'\n",
    "END_DATE = '2022-07-30'\n",
    "df_five_factor = web.DataReader('F-F_Research_Data_5_Factors_2x3', \n",
    "                                'famafrench', \n",
    "                                start=START_DATE)[0]\n",
    "df_five_factor.index = df_five_factor.index.format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72de556",
   "metadata": {},
   "source": [
    "## All the technical indiactors are change into percentage values and multiplied with 100 to get percentages as they have to be in the same format as the five factors and the five factors are in the percentage values. Also the time format is changed to year and month as the five factors are in this format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "391a9b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df['ATR'].pct_change()\n",
    "tr=df2*100\n",
    "tr.index = tr.index.strftime('%Y-%m')\n",
    "df_five_factor['ATR'] = tr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb88aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df['OBV'].pct_change()\n",
    "obv=df3*100\n",
    "obv.index = obv.index.strftime('%Y-%m')\n",
    "df_five_factor['OBV'] = obv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e457665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df['EMA'].pct_change()\n",
    "ema=df4*100\n",
    "ema.index = ema.index.strftime('%Y-%m')\n",
    "df_five_factor['EMA'] = ema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208f899",
   "metadata": {},
   "source": [
    "## Consumer price index (CPI) inflation for United States of America (USA) in the format of comma seperated values (csv) are downloaded form organisation for economic cooperation and development (OCED) website (https://data.oecd.org/price/inflation-cpi.htm)  .  This data is read and added to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a5f62a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi = pd.read_csv('cpi.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be8805",
   "metadata": {},
   "source": [
    "## Long term interest rates(IR) for United States of America (USA) in the format of comma seperated values (csv) are downloaded form organisation for economic cooperation and development (OCED) website (https://data.oecd.org/interest/long-term-interest-rates.htm)  .  This data is read and added to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "21051fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest = pd.read_csv('IR.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7203619",
   "metadata": {},
   "source": [
    "## CPI and IR are also converted in percentages in the steps below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "24bba0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_five_factor['CPI']=cpi.pct_change()*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "63943a74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_five_factor['IR']=interest.pct_change()*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0690e04d",
   "metadata": {},
   "source": [
    "## All the ten parameters which include five factors, technical indicators, and economic data are now converted from percentages to normal values with the stock market index start price as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7673427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_five_factor = 1+df_five_factor/100 # Obtain the rate changes effect as a multiplicative factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c749b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_five_factor =  np.cumprod(df_five_factor) # compute the compounding effect of the rate changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3fe2c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_five_factor = df_five_factor*data.iloc[0,0] # consider the start price value of the index as reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a534df3",
   "metadata": {},
   "source": [
    "## Column length of the dataframe is obtained which can be used to determine the dimensionality of input for our machine learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b38300c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_len = len(list(df_five_factor.columns))\n",
    "col_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17536b35",
   "metadata": {},
   "source": [
    "## Renaming coloumns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ad20ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_five_factor.rename(columns = {'Mkt-RF': 'MKT'} , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8e96b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_five_factor.rename(columns = {'Mom   ': 'MOM'} , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6df9a7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MKT', 'SMB', 'HML', 'RMW', 'CMA', 'RF', 'ATR', 'OBV', 'EMA', 'CPI', 'IR']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_factor=list(df_five_factor.columns)\n",
    "list_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e22de73",
   "metadata": {},
   "source": [
    "## Adjusting the time format of close value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "981357a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.dropna()\n",
    "\n",
    "y.index = y.index.strftime('%Y-%m')\n",
    "y.name = 'return'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f2205e",
   "metadata": {},
   "source": [
    "## Determine the period (how many months) for which you want to forecast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "335e7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_period=24\n",
    "five_factor_data=df_five_factor.shift(predict_period) \n",
    "# advance the factors and other parameters as per the forecast period so that current factors can forecast future values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f430d7c6",
   "metadata": {},
   "source": [
    "## Add the stock index close price (the value that has to be forecasted) to the dataframe containing the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5b800d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "five_factor_data = five_factor_data.join(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59175411",
   "metadata": {},
   "source": [
    "## Remove the row entries with missing values so that data is clean for processing and will not cause any issue while the machine is being trained, validated and tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "55b66ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "five_factor_data = five_factor_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb07367",
   "metadata": {},
   "source": [
    "## Convert all the data into floating point numbers so that computations donot through any errors due to incompatibility of data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a9f56ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "five_factor_data= five_factor_data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "712cb188",
   "metadata": {},
   "outputs": [],
   "source": [
    "five_factor_data=five_factor_data.dropna()\n",
    "five_factor_data2 = five_factor_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9daab0e",
   "metadata": {},
   "source": [
    "## Adjusting the length of the dataset to make it suitable for proper splitting and pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "267b4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "five_factor_data=five_factor_data.iloc[len(five_factor_data)%10:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7659ab47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23292605068778946,\n",
       " 0.9740490166922292,\n",
       " 7,\n",
       " 322,\n",
       " {'1%': -3.4508226600665037,\n",
       "  '5%': -2.870558121868621,\n",
       "  '10%': -2.571574731684734},\n",
       " 4973.387131799391)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "adfuller(five_factor_data['CLOSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985ad231",
   "metadata": {},
   "source": [
    "## Use logarthimic scaling to reduce the non-stationarity of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "854818e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "five_factor_data=abs(five_factor_data) # eliminating the negative sign so that the log operation can be applied on the data.\n",
    "five_factor_data=np.log10(five_factor_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "68b720c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.4366977156109846,\n",
       " 0.5645618851903482,\n",
       " 0,\n",
       " 329,\n",
       " {'1%': -3.4503836022181056,\n",
       "  '5%': -2.8703653471616826,\n",
       "  '10%': -2.571471939191249},\n",
       " -1581.5868526999059)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adfuller(five_factor_data['CLOSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d404f2",
   "metadata": {},
   "source": [
    "## Import sklearn and its functions that are used in this program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "caa1feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8140884",
   "metadata": {},
   "source": [
    "## Split the data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3000d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_five_factor_data, test_five_factor_data = train_test_split(five_factor_data, test_size=0.2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46a3ede",
   "metadata": {},
   "source": [
    "## Import MinMaxScalar and use it to scale the data as machine learning techniques are efficient when working with data in the range 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316322d0",
   "metadata": {},
   "source": [
    "## Scalar associated with train dataset is named 's1' and scalar associated with test dataset is named 's2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dee42769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "s1 = MinMaxScaler(feature_range=(0,1))\n",
    "train_five_factor_data[:]=s1.fit_transform(train_five_factor_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "205134ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = MinMaxScaler(feature_range=(0,1))\n",
    "test_five_factor_data[:]=s2.fit_transform(test_five_factor_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a0b907",
   "metadata": {},
   "source": [
    "## Obtain the column and index names to assign them to dataframe obtained as outputs of the machine learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d0c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a42d6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns=test_five_factor_data.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "106af4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index_test = test_five_factor_data.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "84d51e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index_train = train_five_factor_data.index.to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386b426",
   "metadata": {},
   "source": [
    "## Import statsmodel library and its formula API so that linear regression model using ordinary least squares criteria be implemented. Train the linear regression model using training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7f25434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  CLOSE   R-squared:                       0.867\n",
      "Model:                            OLS   Adj. R-squared:                  0.861\n",
      "Method:                 Least Squares   F-statistic:                     148.8\n",
      "Date:                Thu, 06 Oct 2022   Prob (F-statistic):          1.89e-103\n",
      "Time:                        22:16:13   Log-Likelihood:                 309.04\n",
      "No. Observations:                 264   AIC:                            -594.1\n",
      "Df Residuals:                     252   BIC:                            -551.2\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.1108      0.074      1.500      0.135      -0.035       0.256\n",
      "MKT            0.0810      0.178      0.454      0.650      -0.270       0.432\n",
      "SMB            0.0516      0.078      0.666      0.506      -0.101       0.204\n",
      "HML           -0.2013      0.066     -3.059      0.002      -0.331      -0.072\n",
      "RMW            0.5972      0.083      7.195      0.000       0.434       0.761\n",
      "CMA            0.0923      0.086      1.074      0.284      -0.077       0.262\n",
      "RF            -0.5075      0.089     -5.690      0.000      -0.683      -0.332\n",
      "IR            -0.0266      0.069     -0.388      0.699      -0.162       0.109\n",
      "CPI           -0.0398      0.051     -0.781      0.436      -0.140       0.061\n",
      "ATR            0.0949      0.057      1.656      0.099      -0.018       0.208\n",
      "OBV            0.3688      0.112      3.299      0.001       0.149       0.589\n",
      "EMA            0.3755      0.294      1.279      0.202      -0.203       0.954\n",
      "==============================================================================\n",
      "Omnibus:                       11.777   Durbin-Watson:                   0.177\n",
      "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               22.186\n",
      "Skew:                          -0.191   Prob(JB):                     1.52e-05\n",
      "Kurtosis:                       4.368   Cond. No.                         178.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "five_factor_model = smf.ols(\n",
    "    formula='CLOSE ~ MKT + SMB + HML + RMW + CMA+ RF + IR + CPI + ATR + OBV + EMA', \n",
    "    data=train_five_factor_data\n",
    ").fit()\n",
    "print(five_factor_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c34d1b2",
   "metadata": {},
   "source": [
    "## Predict the close price for test data using the trained linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "49878433",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (five_factor_model.predict(test_five_factor_data.iloc[:,0:col_len]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad542d",
   "metadata": {},
   "source": [
    "## Predict the close price for train data using the trained linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cd8bc874",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = (five_factor_model.predict(train_five_factor_data.iloc[:,0:col_len]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160ba0b8",
   "metadata": {},
   "source": [
    "## Appending predicted values to the train and test dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "88026e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_five_factor_data['LR']=df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "db911f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_five_factor_data['LR']=df_tr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb4390",
   "metadata": {},
   "source": [
    "## Creating dataframes which are similar to train and test data but close prices replaced by predicted data. This is done so that the dimensions match and the inverse transformation of MinMaxScalar are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e92c8271",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = test_five_factor_data[list_factor+['LR']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bd1a5a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_tr = train_five_factor_data[list_factor+['LR']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2571e",
   "metadata": {},
   "source": [
    "## Applying inverse transformation of MinMaxScalar associated to test data and train data to data sets where close is replaced by predicted value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41906e19",
   "metadata": {},
   "source": [
    "## Due to the dimentionality requirement of inverse MinMaxScalar we cannot have close and predicted value in a single dataframe and then apply the inverse scalar. Thus we are doing them seperately and later we will combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "41ad2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[:] = s2.inverse_transform(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d295f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_tr[:] = s1.inverse_transform(new_df_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a636f006",
   "metadata": {},
   "source": [
    "## Applying inverse transformation of logarthimic scaling to test and train like data where close is replaced by predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ca1b1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=10**(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "34faef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_tr=10**(new_df_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e48ad0b",
   "metadata": {},
   "source": [
    "## Applying inverse transform of MinMaxScalar to test and train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "76a876d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_test = test_five_factor_data[list_factor+['CLOSE']]\n",
    "new_df_test[:] = s2.inverse_transform(new_df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "07a3c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = train_five_factor_data[list_factor+['CLOSE']]\n",
    "new_df_train[:] = s1.inverse_transform(new_df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127cdbf",
   "metadata": {},
   "source": [
    "## Applying inverse transformation of logarthimic scaling to test and train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "720c21e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_test=10**(new_df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "08f72445",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train=10**(new_df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af166ef3",
   "metadata": {},
   "source": [
    "## Combining predicted and close value along with input parameters into a single dataframe so that this dataframe can be used for calculating metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "be8bc017",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_test['LR']=new_df['LR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "06caa8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train['LR']=new_df_tr['LR']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a469a",
   "metadata": {},
   "source": [
    "## Import sklearn libraries and associated functions for implementing support vector regression. Random search is used for hyperparameter tuning of penality factor C and gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ef9dadb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 95.59664156488698,\n",
       " 'epsilon': 0.013218371012746116,\n",
       " 'gamma': 0.18839288998793566,\n",
       " 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, norm, lognorm, expon\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy\n",
    "\n",
    "svr=SVR(tol=0.0001)\n",
    "distributions=[{'C': scipy.stats.expon(scale=100), 'gamma': scipy.stats.expon(scale=.1), 'epsilon':scipy.stats.expon(scale=.1),\n",
    "  'kernel': ['rbf']}]\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "svr1 = RandomizedSearchCV(svr, distributions, n_iter=100,random_state=0,scoring=scorer,cv=10)\n",
    "search = svr1.fit(train_five_factor_data.iloc[:,0:col_len], train_five_factor_data.iloc[:,col_len])\n",
    "search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95893e53",
   "metadata": {},
   "source": [
    "## Display the success status of the model in fitting the data. It is zero for success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "41e5909b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_.fit_status_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cd1910",
   "metadata": {},
   "source": [
    "## Calculate the importance of each input factor (use one for only one factor and zeros for other factors to calculate its overall weight or coefficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3cc9f891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2040052 ,  0.16034498,  0.18919832,  0.03402029, -0.04157044,\n",
       "        0.66082598,  0.37166989,  0.56063515,  0.43911123,  0.14780707,\n",
       "        0.44592289])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_imp=np.zeros(train_five_factor_data.iloc[:,0:col_len].shape[1]) # initiate the array to store importance of input parameters\n",
    "for k in range(0,train_five_factor_data.iloc[:,0:col_len].shape[1]):\n",
    "    imp=np.zeros((21,train_five_factor_data.iloc[:,0:col_len].shape[1])) #initiate the array to store values to compute sum\n",
    "    for j in range(0,21): # run from 0 to 1 in steps of 0.05, 0.05 is used within the loop\n",
    "        for i in range(0,train_five_factor_data.iloc[:,0:col_len].shape[1]):\n",
    "            imp[j][k]=j*0.05\n",
    "    w_imp[k]=sum(search.best_estimator_.predict(imp))\n",
    "w_imp/21  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a30cdf1",
   "metadata": {},
   "source": [
    "## Predict the close price using the trained SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2e9b9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = pd.DataFrame(search.best_estimator_.predict(test_five_factor_data.iloc[:,0:col_len]),index=list_index_test,columns=['SVR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d3fc6406",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_tr = pd.DataFrame(search.best_estimator_.predict(train_five_factor_data.iloc[:,0:col_len]),index=list_index_train,columns=['SVR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9feea748",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_five_factor_data['SVR']=y1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b648b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_five_factor_data['SVR']=y1_tr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e41599",
   "metadata": {},
   "source": [
    "## Make necessary dimension changes and apply inverse scalar of MinMaxScalar to SVR predicted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "30030423",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dfsvr_test = test_five_factor_data[list_factor+['SVR']]\n",
    "new_dfsvr_test[:] = s2.inverse_transform(new_dfsvr_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "46aa0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dfsvr_train = train_five_factor_data[list_factor+['SVR']]\n",
    "new_dfsvr_train[:] = s1.inverse_transform(new_dfsvr_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a2400c",
   "metadata": {},
   "source": [
    "## Apply inverse logarithmic scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4a38267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dfsvr_test=10**(new_dfsvr_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d736a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dfsvr_train=10**(new_dfsvr_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14442d9e",
   "metadata": {},
   "source": [
    "## Add SVR prediction results to the existing dataframes for calculating metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ce8e0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_test['SVR']=new_dfsvr_test['SVR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ec74706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train['SVR']=new_dfsvr_train['SVR']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa404dbb",
   "metadata": {},
   "source": [
    "## Import the libraries, functions, and layers necesary to implement the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "60239168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d4946d",
   "metadata": {},
   "source": [
    "## Reshape the data such that it fits the input dimensional requirements of LSTM. LSTM input shape is (number of rows or time steps,1,number of columns or features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "df3dbb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_five_factor_data_re = train_five_factor_data.iloc[:,0:col_len].values.reshape(train_five_factor_data.iloc[:,0:col_len].shape[0],1, train_five_factor_data.iloc[:,0:col_len].shape[1])\n",
    "test_five_factor_data_re = test_five_factor_data.iloc[:,0:col_len].values.reshape(test_five_factor_data.iloc[:,0:col_len].shape[0],1, test_five_factor_data.iloc[:,0:col_len].shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e399c",
   "metadata": {},
   "source": [
    "## Define the regressor for LSTM with hyperparameter tuning, and run hyperparameter tuning using keras tuner with number of layers, units per layer, dropout rate, and leraning rate as hyperparameters. Early stopping is also included while evaluating the model to find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "efa589a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 00m 04s]\n",
      "val_mean_squared_error: 0.2735501527786255\n",
      "\n",
      "Best val_mean_squared_error So Far: 0.07033675909042358\n",
      "Total elapsed time: 00h 01m 23s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in my_dir\\built_in_metrics\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000001B9AFF033D0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 4\n",
      "units0: 112\n",
      "rate0: 30\n",
      "units1: 208\n",
      "rate1: 40\n",
      "lr: 0.0009022079415210089\n",
      "units2: 256\n",
      "rate2: 30\n",
      "units3: 160\n",
      "rate3: 40\n",
      "Score: 0.07033675909042358\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 3\n",
      "units0: 176\n",
      "rate0: 40\n",
      "units1: 208\n",
      "rate1: 30\n",
      "lr: 0.0005343634220268847\n",
      "units2: 176\n",
      "rate2: 40\n",
      "units3: 256\n",
      "rate3: 50\n",
      "units4: 48\n",
      "rate4: 50\n",
      "Score: 0.13849397003650665\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 3\n",
      "units0: 32\n",
      "rate0: 40\n",
      "units1: 128\n",
      "rate1: 40\n",
      "lr: 0.0006906159408436501\n",
      "units2: 144\n",
      "rate2: 40\n",
      "units3: 224\n",
      "rate3: 40\n",
      "units4: 176\n",
      "rate4: 40\n",
      "Score: 0.1916838139295578\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 4\n",
      "units0: 112\n",
      "rate0: 30\n",
      "units1: 144\n",
      "rate1: 30\n",
      "lr: 0.0005218086982564764\n",
      "units2: 240\n",
      "rate2: 40\n",
      "units3: 176\n",
      "rate3: 40\n",
      "units4: 80\n",
      "rate4: 50\n",
      "Score: 0.20442187786102295\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 3\n",
      "units0: 224\n",
      "rate0: 40\n",
      "units1: 112\n",
      "rate1: 40\n",
      "lr: 0.00035797804918054376\n",
      "units2: 144\n",
      "rate2: 40\n",
      "units3: 32\n",
      "rate3: 40\n",
      "units4: 96\n",
      "rate4: 40\n",
      "Score: 0.2521611154079437\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 2\n",
      "units0: 64\n",
      "rate0: 30\n",
      "units1: 208\n",
      "rate1: 40\n",
      "lr: 0.0001462772808938758\n",
      "units2: 240\n",
      "rate2: 40\n",
      "units3: 224\n",
      "rate3: 30\n",
      "Score: 0.27285823225975037\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 2\n",
      "units0: 64\n",
      "rate0: 40\n",
      "units1: 96\n",
      "rate1: 40\n",
      "lr: 0.00017529957488324514\n",
      "units2: 208\n",
      "rate2: 50\n",
      "units3: 64\n",
      "rate3: 50\n",
      "units4: 32\n",
      "rate4: 50\n",
      "Score: 0.2735501527786255\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 2\n",
      "units0: 240\n",
      "rate0: 40\n",
      "units1: 144\n",
      "rate1: 40\n",
      "lr: 6.681248953196665e-05\n",
      "units2: 128\n",
      "rate2: 40\n",
      "units3: 176\n",
      "rate3: 40\n",
      "Score: 0.29150277376174927\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 4\n",
      "units0: 128\n",
      "rate0: 30\n",
      "units1: 80\n",
      "rate1: 50\n",
      "lr: 0.00043925333029596605\n",
      "units2: 16\n",
      "rate2: 30\n",
      "units3: 16\n",
      "rate3: 30\n",
      "Score: 0.29910820722579956\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 3\n",
      "units0: 192\n",
      "rate0: 50\n",
      "units1: 144\n",
      "rate1: 30\n",
      "lr: 0.0001047217795168058\n",
      "units2: 32\n",
      "rate2: 50\n",
      "units3: 240\n",
      "rate3: 40\n",
      "Score: 0.30524125695228577\n"
     ]
    }
   ],
   "source": [
    "def build_regressor(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int(\"num\",min_value=2, max_value=5, step=1)):\n",
    "        model.add(layers.LSTM(units=hp.Int(\"units\"+str(i), min_value=16, max_value=256, step=16), input_dim=col_len,return_sequences=True, activation='tanh'))\n",
    "        model.add(layers.Dropout(rate=0.01*hp.Int(\"rate\"+str(i), min_value=30, max_value= 50, step=10)))\n",
    "    model.add(layers.Dense(units=1))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-3, sampling=\"log\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"mean_squared_error\",\n",
    "        # Objectieve is one of the metrics.\n",
    "        metrics=[keras.metrics.MeanSquaredError()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_regressor,\n",
    "    # The objective name and direction.\n",
    "    # Name is the f\"val_{snake_case_metric_class_name}\".\n",
    "    objective=keras_tuner.Objective(\"val_mean_squared_error\", direction=\"min\"),\n",
    "    max_trials=15,\n",
    "    seed=111,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"built_in_metrics\",\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    x=train_five_factor_data_re,\n",
    "    y=train_five_factor_data.iloc[:,col_len],\n",
    "    validation_data=(test_five_factor_data_re,test_five_factor_data.iloc[:,col_len]),\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(\"val_mean_squared_error\")],\n",
    "    epochs=100,\n",
    "\n",
    ")\n",
    "\n",
    "tuner.results_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0d46dd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_crv = 15\n",
    "\n",
    "models1 = tuner.get_best_models(num_models=num_crv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7dbae",
   "metadata": {},
   "source": [
    "## Do 10-fold cross validation for find the consistent model amoung the top models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3fe81133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "num_splits = 10\n",
    "kf=KFold(n_splits=num_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "37f7dd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0729 - mean_squared_error: 0.0729\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0184 - mean_squared_error: 0.0184\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0707 - mean_squared_error: 0.0707\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0112 - mean_squared_error: 0.0112\n",
      "1/1 [==============================] - 1s 778ms/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0904 - mean_squared_error: 0.0904\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1538 - mean_squared_error: 0.1538\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0872 - mean_squared_error: 0.0872\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1241 - mean_squared_error: 0.1241\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1991 - mean_squared_error: 0.1991\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0748 - mean_squared_error: 0.0748\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1805 - mean_squared_error: 0.1805\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3214 - mean_squared_error: 0.3214\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4094 - mean_squared_error: 0.4094\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1294 - mean_squared_error: 0.1294\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2111 - mean_squared_error: 0.2111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1365 - mean_squared_error: 0.1365\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1937 - mean_squared_error: 0.1937\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2975 - mean_squared_error: 0.2975\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1438 - mean_squared_error: 0.1438\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2766 - mean_squared_error: 0.2766\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4560 - mean_squared_error: 0.4560\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5706 - mean_squared_error: 0.5706\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0144 - mean_squared_error: 0.0144\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1367 - mean_squared_error: 0.1367\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2269 - mean_squared_error: 0.2269\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1503 - mean_squared_error: 0.1503\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2120 - mean_squared_error: 0.2120\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3203 - mean_squared_error: 0.3203\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1611 - mean_squared_error: 0.1611\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2977 - mean_squared_error: 0.2977\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4831 - mean_squared_error: 0.4831\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6040 - mean_squared_error: 0.6040\n",
      "1/1 [==============================] - 1s 773ms/step - loss: 0.0260 - mean_squared_error: 0.0260\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1829 - mean_squared_error: 0.1829\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2863 - mean_squared_error: 0.2863\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2008 - mean_squared_error: 0.2008\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2736 - mean_squared_error: 0.2736\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3973 - mean_squared_error: 0.3973\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2171 - mean_squared_error: 0.2171\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3722 - mean_squared_error: 0.3722\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5776 - mean_squared_error: 0.5776\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7111 - mean_squared_error: 0.7111\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.0319 - mean_squared_error: 0.0319\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2023 - mean_squared_error: 0.2023\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3111 - mean_squared_error: 0.3111\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2222 - mean_squared_error: 0.2222\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2999 - mean_squared_error: 0.2999\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4296 - mean_squared_error: 0.4296\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2422 - mean_squared_error: 0.2422\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4079 - mean_squared_error: 0.4079\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6218 - mean_squared_error: 0.6218\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7589 - mean_squared_error: 0.7589\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.0331 - mean_squared_error: 0.0331\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2020 - mean_squared_error: 0.2020\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3068 - mean_squared_error: 0.3068\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2187 - mean_squared_error: 0.2187\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3004 - mean_squared_error: 0.3004\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4321 - mean_squared_error: 0.4321\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2415 - mean_squared_error: 0.2415\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4049 - mean_squared_error: 0.4049\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6187 - mean_squared_error: 0.6187\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7583 - mean_squared_error: 0.7583\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.0368 - mean_squared_error: 0.0368\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2179 - mean_squared_error: 0.2179\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3332 - mean_squared_error: 0.3332\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2424 - mean_squared_error: 0.2424\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3236 - mean_squared_error: 0.3236\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4580 - mean_squared_error: 0.4580\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2641 - mean_squared_error: 0.2641\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4334 - mean_squared_error: 0.4334\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6558 - mean_squared_error: 0.6558\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7977 - mean_squared_error: 0.7977\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0365 - mean_squared_error: 0.0365\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2199 - mean_squared_error: 0.2199\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3381 - mean_squared_error: 0.3381\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2480 - mean_squared_error: 0.2480\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3339 - mean_squared_error: 0.3339\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4735 - mean_squared_error: 0.4735\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2775 - mean_squared_error: 0.2775\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4490 - mean_squared_error: 0.4490\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6774 - mean_squared_error: 0.6774\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8248 - mean_squared_error: 0.8248\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 0.0390 - mean_squared_error: 0.0390\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2267 - mean_squared_error: 0.2267\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3469 - mean_squared_error: 0.3469\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2551 - mean_squared_error: 0.2551\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3412 - mean_squared_error: 0.3412\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4813 - mean_squared_error: 0.4813\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2833 - mean_squared_error: 0.2833\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4571 - mean_squared_error: 0.4571\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6869 - mean_squared_error: 0.6869\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8352 - mean_squared_error: 0.8352\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.0411 - mean_squared_error: 0.0411\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2327 - mean_squared_error: 0.2327\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3541 - mean_squared_error: 0.3541\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2616 - mean_squared_error: 0.2616\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3489 - mean_squared_error: 0.3489\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4915 - mean_squared_error: 0.4915\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2911 - mean_squared_error: 0.2911\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4656 - mean_squared_error: 0.4656\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6982 - mean_squared_error: 0.6982\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8479 - mean_squared_error: 0.8479\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.0413 - mean_squared_error: 0.0413\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2331 - mean_squared_error: 0.2331\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3544 - mean_squared_error: 0.3544\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2623 - mean_squared_error: 0.2623\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3516 - mean_squared_error: 0.3516\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4953 - mean_squared_error: 0.4953\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2941 - mean_squared_error: 0.2941\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4695 - mean_squared_error: 0.4695\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7030 - mean_squared_error: 0.7030\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8538 - mean_squared_error: 0.8538\n",
      "1/1 [==============================] - 1s 779ms/step - loss: 0.0415 - mean_squared_error: 0.0415\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2341 - mean_squared_error: 0.2341\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3563 - mean_squared_error: 0.3563\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2639 - mean_squared_error: 0.2639\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3528 - mean_squared_error: 0.3528\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4963 - mean_squared_error: 0.4963\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2951 - mean_squared_error: 0.2951\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4708 - mean_squared_error: 0.4708\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7048 - mean_squared_error: 0.7048\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8556 - mean_squared_error: 0.8556\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0417 - mean_squared_error: 0.0417\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2351 - mean_squared_error: 0.2351\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3579 - mean_squared_error: 0.3579\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2655 - mean_squared_error: 0.2655\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3550 - mean_squared_error: 0.3550\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4992 - mean_squared_error: 0.4992\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2977 - mean_squared_error: 0.2977\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4741 - mean_squared_error: 0.4741\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7088 - mean_squared_error: 0.7088\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8602 - mean_squared_error: 0.8602\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0431 - mean_squared_error: 0.0431\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2388 - mean_squared_error: 0.2388\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3625 - mean_squared_error: 0.3625\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2693 - mean_squared_error: 0.2693\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3593 - mean_squared_error: 0.3593\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5043 - mean_squared_error: 0.5043\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3015 - mean_squared_error: 0.3015\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4791 - mean_squared_error: 0.4791\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7148 - mean_squared_error: 0.7148\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8668 - mean_squared_error: 0.8668\n"
     ]
    }
   ],
   "source": [
    "score = pd.DataFrame(index=list(range(num_crv)),columns=list(range(num_splits)))\n",
    "for i in range(0,num_crv):\n",
    "    j=0\n",
    "    for train_index,val_index in kf.split(train_five_factor_data_re):\n",
    "        x_train,x_val=train_five_factor_data_re[train_index],train_five_factor_data_re[val_index]\n",
    "        y_train,y_val=train_five_factor_data.iloc[:,col_len][train_index],train_five_factor_data.iloc[:,col_len][val_index]\n",
    "        score.iloc[i,j]=models1[i].evaluate(x_val,y_val)\n",
    "        j=j+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f0d852ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = pd.DataFrame(index=list(range(num_crv)),columns=list(range(num_splits)))\n",
    "for i in range(0,num_crv):\n",
    "    for j in range(0,num_splits):\n",
    "        arr1.iloc[i,j]=np.array(score)[i][j][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "410ebcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1['sum']=arr1.sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e17f0a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1['sum'].idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196d4e4f",
   "metadata": {},
   "source": [
    "## Assign the topmost consistent model as the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cc4e78cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=models1[arr1['sum'].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "60f2323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.build()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f8258",
   "metadata": {},
   "source": [
    "## Display the best model that is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0492c31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, None, 112)         55552     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 112)         0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 208)         267072    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 208)         0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, None, 256)         476160    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 256)         0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, None, 160)         266880    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, None, 160)         0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 1)           161       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,065,825\n",
      "Trainable params: 1,065,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c781881",
   "metadata": {},
   "source": [
    "## Define early stopping criteria for epoches while fitting the model and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "87f40dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='min', patience=15, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f7af8a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 4s 5ms/step - loss: 0.0354 - mean_squared_error: 0.0354\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0211 - mean_squared_error: 0.0211\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0177 - mean_squared_error: 0.0177\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0153 - mean_squared_error: 0.0153\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0159 - mean_squared_error: 0.0159\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0153 - mean_squared_error: 0.0153\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0135 - mean_squared_error: 0.0135\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0118 - mean_squared_error: 0.0118\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0117 - mean_squared_error: 0.0117\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0142 - mean_squared_error: 0.0142\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0118 - mean_squared_error: 0.0118\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0115 - mean_squared_error: 0.0115\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0101 - mean_squared_error: 0.0101\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0099 - mean_squared_error: 0.0099\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0099 - mean_squared_error: 0.0099\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 103: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b9c3a774c0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(train_five_factor_data_re, train_five_factor_data.iloc[:,col_len] ,batch_size = 8, epochs = 500, verbose=1,callbacks=[callback])#batch_size=20 default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb4b61e",
   "metadata": {},
   "source": [
    "## Calculate importance (overall coefficient) of each input on the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d4713433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.60449378, 0.3978365 , 0.28391062, 0.65568452, 0.44200466,\n",
       "       0.25560781, 0.44630332, 0.49025427, 0.50852562, 0.2535939 ,\n",
       "       0.20928074])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_imp=np.zeros(train_five_factor_data_re.shape[2]) # initiate the array to store importance of input parameters\n",
    "for k in range(0,train_five_factor_data_re.shape[2]):\n",
    "    imp=np.zeros((21,train_five_factor_data_re.shape[2])) #initiate the array to store values to compute sum\n",
    "    for j in range(0,21): # run from 0 to 1 in steps of 0.05, 0.05 is used within the loop\n",
    "        for i in range(0,train_five_factor_data_re.shape[2]):\n",
    "            imp[j][k]=j*0.05\n",
    "    w_imp[k]=sum(best_model.predict(imp.reshape(21,1,train_five_factor_data_re.shape[2])))\n",
    "w_imp/21\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef2149",
   "metadata": {},
   "source": [
    "## Predict the close price using the fit LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7c3b4662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(test_five_factor_data_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5e8c2a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = best_model.predict(train_five_factor_data_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e659c9",
   "metadata": {},
   "source": [
    "## Do the inverse reshapeing so that the data can be obtained in the required format to apply inverse scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2ac9a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(y_pred.reshape(-1,1),index=list_index_test,columns=['LSTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "338e0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tr=pd.DataFrame(y_pred_tr.reshape(-1,1),index=list_index_train,columns=['LSTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0fbc5e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_five_factor_data['LSTM']=y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d6277f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_five_factor_data['LSTM']=y_pred_tr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9e485",
   "metadata": {},
   "source": [
    "## Apply inverse scaling related to MinMaxScalar and logarithm scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "00a73c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dflstm_test = test_five_factor_data[list_factor+['LSTM']]\n",
    "new_dflstm_test[:] = s2.inverse_transform(new_dflstm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e68de17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dflstm_test=10**(new_dflstm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a9daf85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dflstm_train = train_five_factor_data[list_factor+['LSTM']]\n",
    "new_dflstm_train[:] = s1.inverse_transform(new_dflstm_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0a3270bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dflstm_train=10**(new_dflstm_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04006ad",
   "metadata": {},
   "source": [
    "## Make data suitable for calculating metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8cdcdc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_test['LSTM']=new_dflstm_test['LSTM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "897bdc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train['LSTM']=new_dflstm_train['LSTM']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708b0c51",
   "metadata": {},
   "source": [
    "## Reshaping data for inputing it to ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bff9e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_five_factor_data_rec = train_five_factor_data.iloc[:,0:col_len].values.reshape(train_five_factor_data.iloc[:,0:col_len].shape[0],1, train_five_factor_data.iloc[:,0:col_len].shape[1])\n",
    "test_five_factor_data_rec = test_five_factor_data.iloc[:,0:col_len].values.reshape(test_five_factor_data.iloc[:,0:col_len].shape[0],1, test_five_factor_data.iloc[:,0:col_len].shape[1])\n",
    "train_five_factor_data_y=train_five_factor_data.iloc[:,col_len]\n",
    "test_five_factor_data_y=test_five_factor_data.iloc[:,col_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afc68ab",
   "metadata": {},
   "source": [
    "## Define the regressor with hyperparameter tuning for ANN, and do hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a95abe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 00m 01s]\n",
      "val_mean_squared_error: 0.078128881752491\n",
      "\n",
      "Best val_mean_squared_error So Far: 0.018722105771303177\n",
      "Total elapsed time: 00h 00m 16s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in my_dir\\built_in_metrics1\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000001B9D900B370>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 2\n",
      "units0: 240\n",
      "rate0: 40\n",
      "units1: 144\n",
      "rate1: 40\n",
      "lr: 6.681248953196665e-05\n",
      "units2: 128\n",
      "rate2: 40\n",
      "units3: 176\n",
      "rate3: 40\n",
      "Score: 0.018722105771303177\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 4\n",
      "units0: 112\n",
      "rate0: 30\n",
      "units1: 208\n",
      "rate1: 40\n",
      "lr: 0.0009022079415210089\n",
      "units2: 256\n",
      "rate2: 30\n",
      "units3: 160\n",
      "rate3: 40\n",
      "Score: 0.02348429523408413\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 3\n",
      "units0: 224\n",
      "rate0: 40\n",
      "units1: 112\n",
      "rate1: 40\n",
      "lr: 0.00035797804918054376\n",
      "units2: 144\n",
      "rate2: 40\n",
      "units3: 32\n",
      "rate3: 40\n",
      "units4: 96\n",
      "rate4: 40\n",
      "Score: 0.029852472245693207\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 2\n",
      "units0: 64\n",
      "rate0: 30\n",
      "units1: 208\n",
      "rate1: 40\n",
      "lr: 0.0001462772808938758\n",
      "units2: 240\n",
      "rate2: 40\n",
      "units3: 224\n",
      "rate3: 30\n",
      "Score: 0.038486048579216\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 3\n",
      "units0: 176\n",
      "rate0: 40\n",
      "units1: 208\n",
      "rate1: 30\n",
      "lr: 0.0005343634220268847\n",
      "units2: 176\n",
      "rate2: 40\n",
      "units3: 256\n",
      "rate3: 50\n",
      "units4: 48\n",
      "rate4: 50\n",
      "Score: 0.04139279946684837\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 3\n",
      "units0: 192\n",
      "rate0: 50\n",
      "units1: 144\n",
      "rate1: 30\n",
      "lr: 0.0001047217795168058\n",
      "units2: 32\n",
      "rate2: 50\n",
      "units3: 240\n",
      "rate3: 40\n",
      "Score: 0.04466349259018898\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 5\n",
      "units0: 240\n",
      "rate0: 50\n",
      "units1: 48\n",
      "rate1: 40\n",
      "lr: 8.019212661756025e-05\n",
      "units2: 48\n",
      "rate2: 40\n",
      "units3: 240\n",
      "rate3: 40\n",
      "units4: 16\n",
      "rate4: 30\n",
      "Score: 0.04525119066238403\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 3\n",
      "units0: 32\n",
      "rate0: 30\n",
      "units1: 192\n",
      "rate1: 30\n",
      "lr: 6.220323522895685e-05\n",
      "units2: 128\n",
      "rate2: 30\n",
      "units3: 144\n",
      "rate3: 40\n",
      "units4: 144\n",
      "rate4: 40\n",
      "Score: 0.045491430908441544\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 3\n",
      "units0: 32\n",
      "rate0: 40\n",
      "units1: 128\n",
      "rate1: 40\n",
      "lr: 0.0006906159408436501\n",
      "units2: 144\n",
      "rate2: 40\n",
      "units3: 224\n",
      "rate3: 40\n",
      "units4: 176\n",
      "rate4: 40\n",
      "Score: 0.068252794444561\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 2\n",
      "units0: 64\n",
      "rate0: 40\n",
      "units1: 96\n",
      "rate1: 40\n",
      "lr: 0.00017529957488324514\n",
      "units2: 208\n",
      "rate2: 50\n",
      "units3: 64\n",
      "rate3: 50\n",
      "units4: 32\n",
      "rate4: 50\n",
      "Score: 0.078128881752491\n"
     ]
    }
   ],
   "source": [
    "def build_regressor(hp):\n",
    "    model1 = keras.Sequential()\n",
    "    for i in range(hp.Int(\"num\",min_value=2, max_value=5, step=1)):\n",
    "        model1.add(layers.Dense(units=hp.Int(\"units\"+str(i), min_value=16, max_value=256, step=16), activation='tanh'))\n",
    "        model1.add(layers.Dropout(rate=0.01*hp.Int(\"rate\"+str(i), min_value=30, max_value= 50, step=10)))\n",
    "    model1.add(layers.Dense(units=1))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-3, sampling=\"log\")\n",
    "\n",
    "    model1.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"mean_squared_error\",\n",
    "        # Objective is one of the metrics.\n",
    "        metrics=[keras.metrics.MeanSquaredError()],\n",
    "    )\n",
    "    return model1\n",
    "\n",
    "\n",
    "tuner1 = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_regressor,\n",
    "    # The objective name and direction.\n",
    "    # Name is the f\"val_{snake_case_metric_class_name}\".\n",
    "    objective=keras_tuner.Objective(\"val_mean_squared_error\", direction=\"min\"),\n",
    "    max_trials=15,\n",
    "    seed=111,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"built_in_metrics1\",\n",
    ")\n",
    "\n",
    "tuner1.search(\n",
    "    x=train_five_factor_data_rec,\n",
    "    y=train_five_factor_data_y,\n",
    "    validation_data=(test_five_factor_data_rec,test_five_factor_data_y),\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(\"val_mean_squared_error\")],\n",
    "    epochs=100,\n",
    "\n",
    ")\n",
    "\n",
    "tuner1.results_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ee9e83dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_crv = 15\n",
    "\n",
    "models2 = tuner1.get_best_models(num_models=num_crv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e0a98",
   "metadata": {},
   "source": [
    "## Implement 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a2be2f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "num_splits = 10\n",
    "kf1=KFold(n_splits=num_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a00ab32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0102 - mean_squared_error: 0.0102\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0205 - mean_squared_error: 0.0205\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0257 - mean_squared_error: 0.0257\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0166 - mean_squared_error: 0.0166\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0143 - mean_squared_error: 0.0143\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0151 - mean_squared_error: 0.0151\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0138 - mean_squared_error: 0.0138\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0274 - mean_squared_error: 0.0274\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0174 - mean_squared_error: 0.0174\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0247 - mean_squared_error: 0.0247\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.9408e-04 - mean_squared_error: 5.9408e-04\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0491 - mean_squared_error: 0.0491\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0177 - mean_squared_error: 0.0177\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0101 - mean_squared_error: 0.0101\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0203 - mean_squared_error: 0.0203\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0151 - mean_squared_error: 0.0151\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0280 - mean_squared_error: 0.0280\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0482 - mean_squared_error: 0.0482\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0514 - mean_squared_error: 0.0514\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.7627e-04 - mean_squared_error: 5.7627e-04\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0336 - mean_squared_error: 0.0336\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0341 - mean_squared_error: 0.0341\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0110 - mean_squared_error: 0.0110\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0713 - mean_squared_error: 0.0713\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0590 - mean_squared_error: 0.0590\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0269 - mean_squared_error: 0.0269\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1875 - mean_squared_error: 0.1875\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0708 - mean_squared_error: 0.0708\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0300 - mean_squared_error: 0.0300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0233 - mean_squared_error: 0.0233\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0186 - mean_squared_error: 0.0186\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0531 - mean_squared_error: 0.0531\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0561 - mean_squared_error: 0.0561\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0146 - mean_squared_error: 0.0146\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1587 - mean_squared_error: 0.1587\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0706 - mean_squared_error: 0.0706\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0161 - mean_squared_error: 0.0161\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.0289 - mean_squared_error: 0.0289\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0274 - mean_squared_error: 0.0274\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0125 - mean_squared_error: 0.0125\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0622 - mean_squared_error: 0.0622\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1238 - mean_squared_error: 0.1238\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0399 - mean_squared_error: 0.0399\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1840 - mean_squared_error: 0.1840\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2061 - mean_squared_error: 0.2061\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2774 - mean_squared_error: 0.2774\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0547 - mean_squared_error: 0.0547\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0714 - mean_squared_error: 0.0714\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0281 - mean_squared_error: 0.0281\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0118 - mean_squared_error: 0.0118\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0425 - mean_squared_error: 0.0425\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0201 - mean_squared_error: 0.0201\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0115 - mean_squared_error: 0.0115\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0616 - mean_squared_error: 0.0616\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0564 - mean_squared_error: 0.0564\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0354 - mean_squared_error: 0.0354\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0204 - mean_squared_error: 0.0204\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0562 - mean_squared_error: 0.0562\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0205 - mean_squared_error: 0.0205\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0899 - mean_squared_error: 0.0899\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1352 - mean_squared_error: 0.1352\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1319 - mean_squared_error: 0.1319\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0228 - mean_squared_error: 0.0228\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0413 - mean_squared_error: 0.0413\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0249 - mean_squared_error: 0.0249\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0852 - mean_squared_error: 0.0852\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0158 - mean_squared_error: 0.0158\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0244 - mean_squared_error: 0.0244\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0540 - mean_squared_error: 0.0540\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1302 - mean_squared_error: 0.1302\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0179 - mean_squared_error: 0.0179\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0145 - mean_squared_error: 0.0145\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0157 - mean_squared_error: 0.0157\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0552 - mean_squared_error: 0.0552\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1445 - mean_squared_error: 0.1445\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0933 - mean_squared_error: 0.0933\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1353 - mean_squared_error: 0.1353\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0874 - mean_squared_error: 0.0874\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1227 - mean_squared_error: 0.1227\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1730 - mean_squared_error: 0.1730\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0579 - mean_squared_error: 0.0579\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1669 - mean_squared_error: 0.1669\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2994 - mean_squared_error: 0.2994\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3782 - mean_squared_error: 0.3782\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.0482 - mean_squared_error: 0.0482\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0230 - mean_squared_error: 0.0230\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0630 - mean_squared_error: 0.0630\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1814 - mean_squared_error: 0.1814\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1711 - mean_squared_error: 0.1711\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1143 - mean_squared_error: 0.1143\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3571 - mean_squared_error: 0.3571\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1782 - mean_squared_error: 0.1782\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1167 - mean_squared_error: 0.1167\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0934 - mean_squared_error: 0.0934\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0492 - mean_squared_error: 0.0492\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2043 - mean_squared_error: 0.2043\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2422 - mean_squared_error: 0.2422\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1460 - mean_squared_error: 0.1460\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1161 - mean_squared_error: 0.1161\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2077 - mean_squared_error: 0.2077\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0773 - mean_squared_error: 0.0773\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1307 - mean_squared_error: 0.1307\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2121 - mean_squared_error: 0.2121\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3006 - mean_squared_error: 0.3006\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.1212 - mean_squared_error: 0.1212\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0513 - mean_squared_error: 0.0513\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0668 - mean_squared_error: 0.0668\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1713 - mean_squared_error: 0.1713\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1823 - mean_squared_error: 0.1823\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1403 - mean_squared_error: 0.1403\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3687 - mean_squared_error: 0.3687\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1969 - mean_squared_error: 0.1969\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0918 - mean_squared_error: 0.0918\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0559 - mean_squared_error: 0.0559\n"
     ]
    }
   ],
   "source": [
    "score1 = pd.DataFrame(index=list(range(num_crv)),columns=list(range(num_splits)))\n",
    "for i in range(0,num_crv):\n",
    "    j=0\n",
    "    for train_index,val_index in kf1.split(train_five_factor_data_rec):\n",
    "        x_train,x_val=train_five_factor_data_rec[train_index],train_five_factor_data_rec[val_index]\n",
    "        y_train,y_val=train_five_factor_data.iloc[:,col_len][train_index],train_five_factor_data.iloc[:,col_len][val_index]\n",
    "        score1.iloc[i,j]=models2[i].evaluate(x_val,y_val)\n",
    "        j=j+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "edc1cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = pd.DataFrame(index=list(range(num_crv)),columns=list(range(num_splits)))\n",
    "for i in range(0,num_crv):\n",
    "    for j in range(0,num_splits):\n",
    "        arr2.iloc[i,j]=np.array(score1)[i][j][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1f9ecda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2['sum']=arr2.sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b661a53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2['sum'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ebedbb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model1=models2[arr2['sum'].idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d0d12a",
   "metadata": {},
   "source": [
    "## Use the best model to build and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "33453131",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model1.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b88e3eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1, 112)            1344      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 112)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1, 208)            23504     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 208)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1, 256)            53504     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 256)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1, 160)            41120     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 160)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1, 1)              161       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,633\n",
      "Trainable params: 119,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "22cce4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2142 - mean_squared_error: 0.2142\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1351 - mean_squared_error: 0.1351\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0969 - mean_squared_error: 0.0969\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0819 - mean_squared_error: 0.0819\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0720 - mean_squared_error: 0.0720\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0549 - mean_squared_error: 0.0549\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0529 - mean_squared_error: 0.0529\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0448 - mean_squared_error: 0.0448\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0408 - mean_squared_error: 0.0408\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0304 - mean_squared_error: 0.0304\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0334 - mean_squared_error: 0.0334\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0324 - mean_squared_error: 0.0324\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0276 - mean_squared_error: 0.0276\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0265 - mean_squared_error: 0.0265\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0259 - mean_squared_error: 0.0259\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0241 - mean_squared_error: 0.0241\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0209 - mean_squared_error: 0.0209\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0197 - mean_squared_error: 0.0197\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0183 - mean_squared_error: 0.0183\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_squared_error: 0.0188\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0174 - mean_squared_error: 0.0174\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0176 - mean_squared_error: 0.0176\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0193 - mean_squared_error: 0.0193\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0173 - mean_squared_error: 0.0173\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0184 - mean_squared_error: 0.0184\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0159 - mean_squared_error: 0.0159\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0181 - mean_squared_error: 0.0181\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0150 - mean_squared_error: 0.0150\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0173 - mean_squared_error: 0.0173\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0172 - mean_squared_error: 0.0172\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0144 - mean_squared_error: 0.0144\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0157 - mean_squared_error: 0.0157\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0155 - mean_squared_error: 0.0155\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0166 - mean_squared_error: 0.0166\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0157 - mean_squared_error: 0.0157\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0153 - mean_squared_error: 0.0153\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0153 - mean_squared_error: 0.0153\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0145 - mean_squared_error: 0.0145\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0156 - mean_squared_error: 0.0156\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0169 - mean_squared_error: 0.0169\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0148 - mean_squared_error: 0.0148\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0154 - mean_squared_error: 0.0154\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0149 - mean_squared_error: 0.0149\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0131 - mean_squared_error: 0.0131\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0142 - mean_squared_error: 0.0142\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0153 - mean_squared_error: 0.0153\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0126 - mean_squared_error: 0.0126\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0138 - mean_squared_error: 0.0138\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0148 - mean_squared_error: 0.0148\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0134 - mean_squared_error: 0.0134\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0130 - mean_squared_error: 0.0130\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0128 - mean_squared_error: 0.0128\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0127 - mean_squared_error: 0.0127\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0135 - mean_squared_error: 0.0135\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0124 - mean_squared_error: 0.0124\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0137 - mean_squared_error: 0.0137\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0109 - mean_squared_error: 0.0109\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0109 - mean_squared_error: 0.0109\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0117 - mean_squared_error: 0.0117\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0133 - mean_squared_error: 0.0133\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_squared_error: 0.0102\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0119 - mean_squared_error: 0.0119\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0121 - mean_squared_error: 0.0121\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0135 - mean_squared_error: 0.0135\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0110 - mean_squared_error: 0.0110\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_squared_error: 0.0102\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0115 - mean_squared_error: 0.0115\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0116 - mean_squared_error: 0.0116\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0109 - mean_squared_error: 0.0109\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_squared_error: 0.0102\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0101 - mean_squared_error: 0.0101\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 103: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b9e1507e50>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Early stopping criteria is also used.\n",
    "best_model1.fit(train_five_factor_data_rec, train_five_factor_data.iloc[:,col_len] ,batch_size = 8, epochs = 500, verbose=1, callbacks=[callback])#batch_size=20 default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac142dcf",
   "metadata": {},
   "source": [
    "## Calculate importance (overall coefficient) of each input on the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8fc8dd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.51834443, 0.44009604, 0.36822135, 0.60512193, 0.44769696,\n",
       "       0.25119818, 0.45385134, 0.57298797, 0.51821009, 0.36247646,\n",
       "       0.30650239])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_imp=np.zeros(train_five_factor_data_rec.shape[2]) # initiate the array to store importance of input parameters\n",
    "for k in range(0,train_five_factor_data_rec.shape[2]):\n",
    "    imp=np.zeros((21,train_five_factor_data_rec.shape[2])) #initiate the array to store values to compute sum\n",
    "    for j in range(0,21): # run from 0 to 1 in steps of 0.05, 0.05 is used within the loop\n",
    "        for i in range(0,train_five_factor_data_rec.shape[2]):\n",
    "            imp[j][k]=j*0.05\n",
    "    w_imp[k]=sum(best_model1.predict(imp.reshape(21,1,train_five_factor_data_rec.shape[2])))\n",
    "w_imp/21  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e8203",
   "metadata": {},
   "source": [
    "## Predict the output using the best model for ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d1057dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "yc_pred1 = best_model1.predict(test_five_factor_data_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8cc0205e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "yc_pred1_tr = best_model1.predict(train_five_factor_data_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582897f2",
   "metadata": {},
   "source": [
    "## Do necessary reshaping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2e2428dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_pred1=yc_pred1.reshape(yc_pred1.shape[0],1)\n",
    "yc_pred1_tr=yc_pred1_tr.reshape(yc_pred1_tr.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4496dad1",
   "metadata": {},
   "source": [
    "## Convert array into dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "268d4b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1=pd.DataFrame(yc_pred1,index=list_index_test,columns=['ANN'])\n",
    "y_2=pd.DataFrame(yc_pred1_tr,index=list_index_train,columns=['ANN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e6de4d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_five_factor_data['ANN']=y_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "82df5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_five_factor_data['ANN']=y_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d9d73e",
   "metadata": {},
   "source": [
    "## Do inverse transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0b5c9bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dfclstm_test = test_five_factor_data[list_factor+['ANN']]\n",
    "new_dfclstm_test[:] = s2.inverse_transform(new_dfclstm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6f5cb1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dfclstm_test=10**(new_dfclstm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d87d11fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dfclstm_train = train_five_factor_data[list_factor+['ANN']]\n",
    "new_dfclstm_train[:] = s1.inverse_transform(new_dfclstm_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f2ebee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dfclstm_train=10**(new_dfclstm_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b3dd3500",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_test['ANN']=new_dfclstm_test['ANN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d6622150",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train['ANN']=new_dfclstm_train['ANN']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e029e8",
   "metadata": {},
   "source": [
    "## Compute the root mean square error for comparision of performance of various models used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "50b97fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3604.4845739444017, 5053.33639085165, 4355.912249254291, 2983.297934972057)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms_lr = sqrt(mean_squared_error(new_df_test['CLOSE'],new_df_test['LR']))\n",
    "rms_svr = sqrt(mean_squared_error(new_df_test['CLOSE'],new_df_test['SVR']))\n",
    "rms_lstm = sqrt(mean_squared_error(new_df_test['CLOSE'],new_df_test['LSTM']))\n",
    "rms_ANN = sqrt(mean_squared_error(new_df_test['CLOSE'],new_df_test['ANN']))\n",
    "rms_lr, rms_svr, rms_lstm, rms_ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c61b00f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1228.738895904747, 463.73322827900915, 1017.5132403389813, 1350.5845824899027)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms_lr_tr = sqrt(mean_squared_error(new_df_train['CLOSE'],new_df_train['LR']))\n",
    "rms_svr_tr = sqrt(mean_squared_error(new_df_train['CLOSE'],new_df_train['SVR']))\n",
    "rms_lstm_tr = sqrt(mean_squared_error(new_df_train['CLOSE'],new_df_train['LSTM']))\n",
    "rms_ANN_tr = sqrt(mean_squared_error(new_df_train['CLOSE'],new_df_train['ANN']))\n",
    "rms_lr_tr, rms_svr_tr, rms_lstm_tr, rms_ANN_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27c0bb6",
   "metadata": {},
   "source": [
    "## Compute the mean absolute percentage error for comparision of performance of various models used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "cfcea385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10556097858165692,\n",
       " 0.1449511782886755,\n",
       " 0.14825561308364718,\n",
       " 0.09483705231984074)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "mape_lr = mean_absolute_percentage_error(new_df_test['CLOSE'],new_df_test['LR'])\n",
    "mape_svr = mean_absolute_percentage_error(new_df_test['CLOSE'],new_df_test['SVR'])\n",
    "mape_lstm = mean_absolute_percentage_error(new_df_test['CLOSE'],new_df_test['LSTM'])\n",
    "mape_ANN = mean_absolute_percentage_error(new_df_test['CLOSE'],new_df_test['ANN'])\n",
    "mape_lr, mape_svr, mape_lstm, mape_ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e108d9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08968471540504219,\n",
       " 0.03206710897065926,\n",
       " 0.06809542845473876,\n",
       " 0.10163890699710597)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_lr_tr = mean_absolute_percentage_error(new_df_train['CLOSE'],new_df_train['LR'])\n",
    "mape_svr_tr = mean_absolute_percentage_error(new_df_train['CLOSE'],new_df_train['SVR'])\n",
    "mape_lstm_tr = mean_absolute_percentage_error(new_df_train['CLOSE'],new_df_train['LSTM'])\n",
    "mape_ANN_tr = mean_absolute_percentage_error(new_df_train['CLOSE'],new_df_train['ANN'])\n",
    "mape_lr_tr, mape_svr_tr, mape_lstm_tr, mape_ANN_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f70a1",
   "metadata": {},
   "source": [
    "## Define the MinMaxScalar and use them along with long scaling to scale the data for stage two of the hybrid technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "adcfec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_2=MinMaxScaler(feature_range=(0,1))\n",
    "s2_2=MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "01e74def",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_test=new_df_test[['LR','SVR','LSTM','ANN','CLOSE']]\n",
    "stage2_test[:]=s2_2.fit_transform(np.log10(abs(stage2_test)))\n",
    "stage2_test_data=stage2_test[['LR','SVR','LSTM','ANN']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "59c1f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_train=new_df_train[['LR','SVR','LSTM','ANN','CLOSE']]\n",
    "stage2_train[:]=s1_2.fit_transform(np.log10(abs(stage2_train)))\n",
    "stage2_train_data=stage2_train[['LR','SVR','LSTM','ANN']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddcef97",
   "metadata": {},
   "source": [
    "## Shape the dimensions of the data to fit the model requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "73a812a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_len_2=len(list(stage2_train.columns))-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "99ccfed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_five_factor_data_2 = stage2_train.iloc[:,0:col_len_2].values.reshape(stage2_train.iloc[:,0:col_len_2].shape[0],1, stage2_train.iloc[:,0:col_len_2].shape[1])\n",
    "test_five_factor_data_2 = stage2_test.iloc[:,0:col_len_2].values.reshape(stage2_test.iloc[:,0:col_len_2].shape[0],1, stage2_test.iloc[:,0:col_len_2].shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b5cb2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_five_factor_data_2_y=stage2_train.iloc[:,col_len_2]\n",
    "test_five_factor_data_2_y=stage2_test.iloc[:,col_len_2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a166caf2",
   "metadata": {},
   "source": [
    "## Define the model along with hyperparameter tuning and compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2a29b26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 00m 04s]\n",
      "val_mean_squared_error: 0.29043909907341003\n",
      "\n",
      "Best val_mean_squared_error So Far: 0.0621536485850811\n",
      "Total elapsed time: 00h 01m 26s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in my_dir\\built_in_metrics3\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000001B9E17338E0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 4\n",
      "units0: 112\n",
      "rate0: 30\n",
      "units1: 208\n",
      "rate1: 40\n",
      "lr: 0.0009022079415210089\n",
      "units2: 256\n",
      "rate2: 30\n",
      "units3: 160\n",
      "rate3: 40\n",
      "Score: 0.0621536485850811\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 3\n",
      "units0: 176\n",
      "rate0: 40\n",
      "units1: 208\n",
      "rate1: 30\n",
      "lr: 0.0005343634220268847\n",
      "units2: 176\n",
      "rate2: 40\n",
      "units3: 256\n",
      "rate3: 50\n",
      "units4: 48\n",
      "rate4: 50\n",
      "Score: 0.19090750813484192\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 3\n",
      "units0: 32\n",
      "rate0: 40\n",
      "units1: 128\n",
      "rate1: 40\n",
      "lr: 0.0006906159408436501\n",
      "units2: 144\n",
      "rate2: 40\n",
      "units3: 224\n",
      "rate3: 40\n",
      "units4: 176\n",
      "rate4: 40\n",
      "Score: 0.21678368747234344\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 4\n",
      "units0: 112\n",
      "rate0: 30\n",
      "units1: 144\n",
      "rate1: 30\n",
      "lr: 0.0005218086982564764\n",
      "units2: 240\n",
      "rate2: 40\n",
      "units3: 176\n",
      "rate3: 40\n",
      "units4: 80\n",
      "rate4: 50\n",
      "Score: 0.22213530540466309\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 3\n",
      "units0: 224\n",
      "rate0: 40\n",
      "units1: 112\n",
      "rate1: 40\n",
      "lr: 0.00035797804918054376\n",
      "units2: 144\n",
      "rate2: 40\n",
      "units3: 32\n",
      "rate3: 40\n",
      "units4: 96\n",
      "rate4: 40\n",
      "Score: 0.2592458426952362\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 2\n",
      "units0: 64\n",
      "rate0: 40\n",
      "units1: 96\n",
      "rate1: 40\n",
      "lr: 0.00017529957488324514\n",
      "units2: 208\n",
      "rate2: 50\n",
      "units3: 64\n",
      "rate3: 50\n",
      "units4: 32\n",
      "rate4: 50\n",
      "Score: 0.29043909907341003\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 2\n",
      "units0: 64\n",
      "rate0: 30\n",
      "units1: 208\n",
      "rate1: 40\n",
      "lr: 0.0001462772808938758\n",
      "units2: 240\n",
      "rate2: 40\n",
      "units3: 224\n",
      "rate3: 30\n",
      "Score: 0.2918965220451355\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 2\n",
      "units0: 240\n",
      "rate0: 40\n",
      "units1: 144\n",
      "rate1: 40\n",
      "lr: 6.681248953196665e-05\n",
      "units2: 128\n",
      "rate2: 40\n",
      "units3: 176\n",
      "rate3: 40\n",
      "Score: 0.2945016324520111\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 4\n",
      "units0: 128\n",
      "rate0: 30\n",
      "units1: 80\n",
      "rate1: 50\n",
      "lr: 0.00043925333029596605\n",
      "units2: 16\n",
      "rate2: 30\n",
      "units3: 16\n",
      "rate3: 30\n",
      "Score: 0.30258822441101074\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num: 3\n",
      "units0: 192\n",
      "rate0: 50\n",
      "units1: 144\n",
      "rate1: 30\n",
      "lr: 0.0001047217795168058\n",
      "units2: 32\n",
      "rate2: 50\n",
      "units3: 240\n",
      "rate3: 40\n",
      "Score: 0.31184616684913635\n"
     ]
    }
   ],
   "source": [
    "def build_regressor(hp):\n",
    "    model3 = keras.Sequential()\n",
    "    for i in range(hp.Int(\"num\",min_value=2, max_value=5, step=1)):\n",
    "        model3.add(layers.LSTM(units=hp.Int(\"units\"+str(i), min_value=16, max_value=256, step=16), input_dim=col_len_2,return_sequences=True, activation='tanh'))\n",
    "        model3.add(layers.Dropout(rate=0.01*hp.Int(\"rate\"+str(i), min_value=30, max_value= 50, step=10)))\n",
    "    model3.add(layers.Dense(units=1))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-3, sampling=\"log\")\n",
    "\n",
    "    model3.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"mean_squared_error\",\n",
    "        # Objective is one of the metrics.\n",
    "        metrics=[keras.metrics.MeanSquaredError()],\n",
    "    )\n",
    "    return model3\n",
    "\n",
    "\n",
    "tuner3 = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_regressor,\n",
    "    # The objective name and direction.\n",
    "    # Name is the f\"val_{snake_case_metric_class_name}\".\n",
    "    objective=keras_tuner.Objective(\"val_mean_squared_error\", direction=\"min\"),\n",
    "    max_trials=15,\n",
    "    seed=111,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"built_in_metrics3\",\n",
    ")\n",
    "\n",
    "tuner3.search(\n",
    "    x=train_five_factor_data_2,\n",
    "    y=train_five_factor_data_2_y,\n",
    "    validation_data=(test_five_factor_data_2,test_five_factor_data_2_y),\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(\"val_mean_squared_error\")],\n",
    "    epochs=100,\n",
    "\n",
    ")\n",
    "\n",
    "tuner3.results_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3067a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_crv = 15\n",
    "models3 = tuner3.get_best_models(num_models=num_crv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90500eb5",
   "metadata": {},
   "source": [
    "## Perform 10 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ac8cdf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "num_splits = 10\n",
    "kf3=KFold(n_splits=num_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b160b04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0162 - mean_squared_error: 0.0162\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0175 - mean_squared_error: 0.0175\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0394 - mean_squared_error: 0.0394\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0201 - mean_squared_error: 0.0201\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0860 - mean_squared_error: 0.0860\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0229 - mean_squared_error: 0.0229\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0655 - mean_squared_error: 0.0655\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1207 - mean_squared_error: 0.1207\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1672 - mean_squared_error: 0.1672\n",
      "1/1 [==============================] - 1s 770ms/step - loss: 0.0168 - mean_squared_error: 0.0168\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1343 - mean_squared_error: 0.1343\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2141 - mean_squared_error: 0.2141\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1513 - mean_squared_error: 0.1513\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2106 - mean_squared_error: 0.2106\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3195 - mean_squared_error: 0.3195\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1671 - mean_squared_error: 0.1671\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2919 - mean_squared_error: 0.2919\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4488 - mean_squared_error: 0.4488\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5565 - mean_squared_error: 0.5565\n",
      "1/1 [==============================] - 1s 779ms/step - loss: 0.0183 - mean_squared_error: 0.0183\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1494 - mean_squared_error: 0.1494\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2409 - mean_squared_error: 0.2409\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1704 - mean_squared_error: 0.1704\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2377 - mean_squared_error: 0.2377\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3554 - mean_squared_error: 0.3554\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1918 - mean_squared_error: 0.1918\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3303 - mean_squared_error: 0.3303\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5129 - mean_squared_error: 0.5129\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6354 - mean_squared_error: 0.6354\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0178 - mean_squared_error: 0.0178\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1510 - mean_squared_error: 0.1510\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2453 - mean_squared_error: 0.2453\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1729 - mean_squared_error: 0.1729\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2423 - mean_squared_error: 0.2423\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3619 - mean_squared_error: 0.3619\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1960 - mean_squared_error: 0.1960\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3377 - mean_squared_error: 0.3377\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5274 - mean_squared_error: 0.5274\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6536 - mean_squared_error: 0.6536\n",
      "1/1 [==============================] - 1s 775ms/step - loss: 0.0282 - mean_squared_error: 0.0282\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1876 - mean_squared_error: 0.1876\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2924 - mean_squared_error: 0.2924\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2123 - mean_squared_error: 0.2123\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2893 - mean_squared_error: 0.2893\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4188 - mean_squared_error: 0.4188\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2378 - mean_squared_error: 0.2378\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3929 - mean_squared_error: 0.3929\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5967 - mean_squared_error: 0.5967\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7307 - mean_squared_error: 0.7307\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.0370 - mean_squared_error: 0.0370\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2157 - mean_squared_error: 0.2157\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3294 - mean_squared_error: 0.3294\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2431 - mean_squared_error: 0.2431\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3263 - mean_squared_error: 0.3263\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4633 - mean_squared_error: 0.4633\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2715 - mean_squared_error: 0.2715\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4374 - mean_squared_error: 0.4374\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6554 - mean_squared_error: 0.6554\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7975 - mean_squared_error: 0.7975\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.0370 - mean_squared_error: 0.0370\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2172 - mean_squared_error: 0.2172\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3318 - mean_squared_error: 0.3318\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2446 - mean_squared_error: 0.2446\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3285 - mean_squared_error: 0.3285\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4673 - mean_squared_error: 0.4673\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2729 - mean_squared_error: 0.2729\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4404 - mean_squared_error: 0.4404\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6597 - mean_squared_error: 0.6597\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8026 - mean_squared_error: 0.8026\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.0391 - mean_squared_error: 0.0391\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2205 - mean_squared_error: 0.2205\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3350 - mean_squared_error: 0.3350\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2482 - mean_squared_error: 0.2482\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3319 - mean_squared_error: 0.3319\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4697 - mean_squared_error: 0.4697\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2766 - mean_squared_error: 0.2766\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4434 - mean_squared_error: 0.4434\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6612 - mean_squared_error: 0.6612\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8035 - mean_squared_error: 0.8035\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0373 - mean_squared_error: 0.0373\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2224 - mean_squared_error: 0.2224\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3417 - mean_squared_error: 0.3417\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2517 - mean_squared_error: 0.2517\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3388 - mean_squared_error: 0.3388\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4799 - mean_squared_error: 0.4799\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2830 - mean_squared_error: 0.2830\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4551 - mean_squared_error: 0.4551\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6849 - mean_squared_error: 0.6849\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8335 - mean_squared_error: 0.8335\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.0409 - mean_squared_error: 0.0409\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2319 - mean_squared_error: 0.2319\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3533 - mean_squared_error: 0.3533\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2618 - mean_squared_error: 0.2618\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3504 - mean_squared_error: 0.3504\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4935 - mean_squared_error: 0.4935\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2935 - mean_squared_error: 0.2935\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4682 - mean_squared_error: 0.4682\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7003 - mean_squared_error: 0.7003\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8502 - mean_squared_error: 0.8502\n",
      "1/1 [==============================] - 1s 827ms/step - loss: 0.0412 - mean_squared_error: 0.0412\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2325 - mean_squared_error: 0.2325\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3541 - mean_squared_error: 0.3541\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2625 - mean_squared_error: 0.2625\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3511 - mean_squared_error: 0.3511\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4944 - mean_squared_error: 0.4944\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2941 - mean_squared_error: 0.2941\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4690 - mean_squared_error: 0.4690\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7013 - mean_squared_error: 0.7013\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8513 - mean_squared_error: 0.8513\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.0418 - mean_squared_error: 0.0418\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2342 - mean_squared_error: 0.2342\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3562 - mean_squared_error: 0.3562\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2643 - mean_squared_error: 0.2643\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3532 - mean_squared_error: 0.3532\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4969 - mean_squared_error: 0.4969\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2960 - mean_squared_error: 0.2960\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4715 - mean_squared_error: 0.4715\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7043 - mean_squared_error: 0.7043\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8547 - mean_squared_error: 0.8547\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0418 - mean_squared_error: 0.0418\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2350 - mean_squared_error: 0.2350\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3576 - mean_squared_error: 0.3576\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2653 - mean_squared_error: 0.2653\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3546 - mean_squared_error: 0.3546\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4987 - mean_squared_error: 0.4987\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2974 - mean_squared_error: 0.2974\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4735 - mean_squared_error: 0.4735\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7077 - mean_squared_error: 0.7077\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8588 - mean_squared_error: 0.8588\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0417 - mean_squared_error: 0.0417\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2350 - mean_squared_error: 0.2350\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3578 - mean_squared_error: 0.3578\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2654 - mean_squared_error: 0.2654\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3549 - mean_squared_error: 0.3549\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4991 - mean_squared_error: 0.4991\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2976 - mean_squared_error: 0.2976\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4740 - mean_squared_error: 0.4740\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7086 - mean_squared_error: 0.7086\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8600 - mean_squared_error: 0.8600\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0433 - mean_squared_error: 0.0433\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2392 - mean_squared_error: 0.2392\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3630 - mean_squared_error: 0.3630\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2699 - mean_squared_error: 0.2699\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3600 - mean_squared_error: 0.3600\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5052 - mean_squared_error: 0.5052\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3023 - mean_squared_error: 0.3023\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4799 - mean_squared_error: 0.4799\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7158 - mean_squared_error: 0.7158\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8679 - mean_squared_error: 0.8679\n"
     ]
    }
   ],
   "source": [
    "score3 = pd.DataFrame(index=list(range(num_crv)),columns=list(range(num_splits)))\n",
    "for i in range(0,num_crv):\n",
    "    j=0\n",
    "    for train_index,val_index in kf3.split(train_five_factor_data_2):\n",
    "        x_train,x_val=train_five_factor_data_2[train_index],train_five_factor_data_2[val_index]\n",
    "        y_train,y_val=train_five_factor_data_2_y[train_index],train_five_factor_data_2_y[val_index]\n",
    "        score3.iloc[i,j]=models3[i].evaluate(x_val,y_val)\n",
    "        j=j+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "eefc59d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3 = pd.DataFrame(index=list(range(num_crv)),columns=list(range(num_splits)))\n",
    "for i in range(0,num_crv):\n",
    "    for j in range(0,num_splits):\n",
    "        arr3.iloc[i,j]=np.array(score3)[i][j][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a18f534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3['sum']=arr3.sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "092bc77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3['sum'].idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aaaa3b",
   "metadata": {},
   "source": [
    "## Select the best model after cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0c5f1d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model3=models3[arr3['sum'].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ed1f033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model3.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b4897c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, None, 112)         52416     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 112)         0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 208)         267072    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 208)         0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, None, 256)         476160    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 256)         0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, None, 160)         266880    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, None, 160)         0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 1)           161       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,062,689\n",
      "Trainable params: 1,062,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model3.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca1c275",
   "metadata": {},
   "source": [
    "## Fit the train data with the best model obtained and predict the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7381afe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 4s 7ms/step - loss: 0.0334 - mean_squared_error: 0.0334\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0158 - mean_squared_error: 0.0158\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0105 - mean_squared_error: 0.0105\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 78: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b9fd9ec730>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model3.fit(train_five_factor_data_2, train_five_factor_data_2_y ,batch_size = 8, epochs = 500, verbose=1, callbacks=[callback])#batch_size=20 default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e34961d",
   "metadata": {},
   "source": [
    "## Importance of LR, SVR, LSTM, ANN predicted values on stage two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "530a18af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.39538731e-05,  4.67769986e-01,  8.28707105e-02, -7.45407598e-03])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_imp=np.zeros(train_five_factor_data_2.shape[2]) # initiate the array to store importance of input parameters\n",
    "for k in range(0,train_five_factor_data_2.shape[2]):\n",
    "    imp=np.zeros((21,train_five_factor_data_2.shape[2])) #initiate the array to store values to compute sum\n",
    "    for j in range(0,21): # run from 0 to 1 in steps of 0.05, 0.05 is used within the loop\n",
    "        for i in range(0,train_five_factor_data_2.shape[2]):\n",
    "            imp[j][k]=j*0.05\n",
    "    w_imp[k]=sum(best_model3.predict(imp.reshape(21,1,train_five_factor_data_2.shape[2])))\n",
    "w_imp/21  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "51d5fc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "yc_pred3 = best_model3.predict(test_five_factor_data_2)\n",
    "yc_pred3_tr = best_model3.predict(train_five_factor_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831943be",
   "metadata": {},
   "source": [
    "## Reshape the data and apply inverse transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5fbaf9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_pred3=yc_pred3.reshape(yc_pred3.shape[0],1)\n",
    "yc_pred3_tr=yc_pred3_tr.reshape(yc_pred3_tr.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "66651027",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_2=pd.DataFrame(yc_pred3,index=list_index_test,columns=['LSTM_2'])\n",
    "pred_train_2=pd.DataFrame(yc_pred3_tr,index=list_index_train,columns=['LSTM_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3208ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_test_data['LSTM_2']=pred_test_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5064f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_train_data['LSTM_2']=pred_train_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "681cf1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_test_data[:] = s2_2.inverse_transform(stage2_test_data)\n",
    "stage2_train_data[:] = s1_2.inverse_transform(stage2_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9a4076db",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_test_data= 10**(stage2_test_data)\n",
    "stage2_train_data= 10**(stage2_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "73803b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_test_data['CLOSE']=new_df_test['CLOSE']\n",
    "stage2_train_data['CLOSE']=new_df_train['CLOSE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e566267d",
   "metadata": {},
   "source": [
    "## Calculating the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3a361901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3604.4845739444017,\n",
       " 5053.33639085165,\n",
       " 4355.912249254293,\n",
       " 2983.297934972057,\n",
       " 5430.5557103612855)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms_lr = sqrt(mean_squared_error(stage2_test_data['CLOSE'],stage2_test_data['LR']))\n",
    "rms_svr = sqrt(mean_squared_error(stage2_test_data['CLOSE'],stage2_test_data['SVR']))\n",
    "rms_lstm = sqrt(mean_squared_error(stage2_test_data['CLOSE'],stage2_test_data['LSTM']))\n",
    "rms_ANN = sqrt(mean_squared_error(stage2_test_data['CLOSE'],stage2_test_data['ANN']))\n",
    "rms_lstm_2 = sqrt(mean_squared_error(stage2_test_data['CLOSE'],stage2_test_data['LSTM_2']))\n",
    "rms_lr, rms_svr, rms_lstm, rms_ANN, rms_lstm_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0ca46722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1228.7388959047469,\n",
       " 463.7332282790089,\n",
       " 1017.5132403389815,\n",
       " 1350.5845824899025,\n",
       " 485.5298000768504)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms_lr_tr = sqrt(mean_squared_error(stage2_train_data['CLOSE'],stage2_train_data['LR']))\n",
    "rms_svr_tr = sqrt(mean_squared_error(stage2_train_data['CLOSE'],stage2_train_data['SVR']))\n",
    "rms_lstm_tr = sqrt(mean_squared_error(stage2_train_data['CLOSE'],stage2_train_data['LSTM']))\n",
    "rms_ANN_tr = sqrt(mean_squared_error(stage2_train_data['CLOSE'],stage2_train_data['ANN']))\n",
    "rms_lstm_2_tr = sqrt(mean_squared_error(stage2_train_data['CLOSE'],stage2_train_data['LSTM_2']))\n",
    "rms_lr_tr, rms_svr_tr, rms_lstm_tr, rms_ANN_tr, rms_lstm_2_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7bb348a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10556097858165692,\n",
       " 0.1449511782886755,\n",
       " 0.1482556130836472,\n",
       " 0.09483705231984074,\n",
       " 0.16078206127805575)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_lr = mean_absolute_percentage_error(stage2_test_data['CLOSE'],stage2_test_data['LR'])\n",
    "mape_svr = mean_absolute_percentage_error(stage2_test_data['CLOSE'],stage2_test_data['SVR'])\n",
    "mape_lstm = mean_absolute_percentage_error(stage2_test_data['CLOSE'],stage2_test_data['LSTM'])\n",
    "mape_ANN = mean_absolute_percentage_error(stage2_test_data['CLOSE'],stage2_test_data['ANN'])\n",
    "mape_lstm_2 = mean_absolute_percentage_error(stage2_test_data['CLOSE'],stage2_test_data['LSTM_2'])\n",
    "mape_lr, mape_svr, mape_lstm, mape_ANN, mape_lstm_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "43a3d6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08968471540504218,\n",
       " 0.032067108970659224,\n",
       " 0.06809542845473879,\n",
       " 0.10163890699710597,\n",
       " 0.03380193673774823)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_lr_tr = mean_absolute_percentage_error(stage2_train_data['CLOSE'],stage2_train_data['LR'])\n",
    "mape_svr_tr = mean_absolute_percentage_error(stage2_train_data['CLOSE'],stage2_train_data['SVR'])\n",
    "mape_lstm_tr = mean_absolute_percentage_error(stage2_train_data['CLOSE'],stage2_train_data['LSTM'])\n",
    "mape_ANN_tr = mean_absolute_percentage_error(stage2_train_data['CLOSE'],stage2_train_data['ANN'])\n",
    "mape_lstm_2_tr = mean_absolute_percentage_error(stage2_train_data['CLOSE'],stage2_train_data['LSTM_2'])\n",
    "mape_lr_tr, mape_svr_tr, mape_lstm_tr, mape_ANN_tr, mape_lstm_2_tr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
